head(st)
names(st)
group_by(st,`years(value)`,weekdays)
st<-mutate(ST,myyear(value),myweekday(value))
st<-mutate(ST,myyear=year(value),myweekday=weekdays(value))
head(st)
group_by(st,myyear,myweekday)
summarise(st)
table(st)
addmargins(table(st$myyear,st$myweekday))
table(st$myyear,st$myweekday)
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(f))
dt <- merge(dt2, fedstats, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
dt
dt2
furl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
lurl<-"./data/work.csv"
download(furl,lurl,mode="wb")
dat1<-fread(lurl,sep=",",skip=5,header=FALSE,col.names=c("CountryCode","GDPRNK","JNK0","NAME","GDP","JNK1","JNK2","JNK3","JNK4","JNK5"))
DT<-tbl_df(dat1)
head(DT)
dt<-mutate(DT,GDP=gsub(",","",GDP))
dt2<-select(dt,NAME,GDP)
dt3<-mutate(dt2,GDP2=as.numeric(GDP))
g<-dt3$GDP2
g<-g[1:190]
mean(g)
#Q4
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(f))
dt <- merge(dt2, fedstats, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
dt2
dt
furl="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
lurl<-"./data/work.csv"
download(furl,lurl,mode="wb")
dat1<-fread(lurl,sep=",",skip=5,header=FALSE,col.names=c("CountryCode","GDPRNK","JNK0","NAME","GDP","JNK1","JNK2","JNK3","JNK4","JNK5"))
DT<-tbl_df(dat1)
head(DT)
dt<-mutate(DT,GDP=gsub(",","",GDP))
dt2<-select(dt,CountryCode,NAME,GDP)
dt3<-mutate(dt2,GDP2=as.numeric(GDP))
g<-dt3$GDP2
g<-g[1:190]
mean(g)
#Q4
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(f))
dt <- merge(dt2, fedstats, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
dt2
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(lurl))
dt <- merge(dt2, fedstats, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(lurl))
dt <- merge(dt2, fedstat, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
dt
glimpse(dt)
dt$Special.Notes
dt$GDP
furl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
lurl <- "EDSTATS_Country.csv"
download(furl,lurl,mode="wb")
fedstat <- data.table(read.csv(lurl))
dt <- merge(dt2, fedstat, all = TRUE, by = c("CountryCode"))
isFiscalYearEnd <- grepl("fiscal year end", tolower(dt$Special.Notes))
isJune <- grepl("june", tolower(dt$Special.Notes))
table(isFiscalYearEnd, isJune)
rm(list=ls())
install.packages("ggplot2")
#Load some libraries I like to work with
library(downloader)
library(data.table)
library(reshape2)
library(curl)
library(dplyr)
library(tidyr)
library(ggplot2)
read.csv(https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv,sep=",")
avgpm25<-fread(https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv,sep=",")
prjdir<-"C:/Users/e41538/Desktop/GitHub/course_4_wk1"
furl<-"https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv"
fn<-paste0(prjdir,"apm25",sep="/")
download.file(furl,fn)
avgpm25<-fread(fn,sep=",")
prjdir<-"C:/Users/e41538/Desktop/GitHub/course_4_wk1"
furl<-"https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv"
fn<-paste(prjdir,"apm25",sep="/")
download.file(furl,fn)
avgpm25<-fread(fn,sep=",")
prjdir<-"C:/Users/e41538/Desktop/GitHub/course_4_wk1"
furl<-"https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv"
"https://github.com/jtleek/modules/blob/master/04_ExploratoryAnalysis/exploratoryGraphs/data/avgpm25.csv"
fn<-paste(prjdir,"apm25",sep="/")
download.file(furl,fn)
library(datasets)
with(faithful,plot(eruptions,waiting))
title(main="Old Faithful eruptions")
pdf(file="myplot.pdf")
library(datasets)
with(faithful,plot(eruptions,waiting))
title(main="Old Faithful eruptions")
dev.off()
pdf(file=paste(prjdir,"plot.pdf",sep="/"))
library(datasets)
with(faithful,plot(eruptions,waiting))
title(main="Old Faithful eruptions")
dev.off()
library(datasets)
with(faithful,plot(eruptions>3,waiting,col=3))
title(main="Old Faithful eruptions")
with(faithful,plot(eruptions,waiting,col=3))
title(main="Old Faithful eruptions")
with(faithful,plot(eruptions,waiting,col=heat.colors(10),main="heat.colors()))
title(main="Old Faithful eruptions")
with(faithful,plot(eruptions,waiting,col=heat.colors(10),main="heat.colors()"))
title(main="Old Faithful eruptions")
par(mfrom=c(1,2))
with(faithful,plot(eruptions,waiting,col=heat.colors(10),main="heat.colors()"))
image(volcano,col=heat.colors(10),main="heat.colors()")))
image(volcano,col=heat.colors(10),main="heat.colors()"))
image(volcano,col=heat.colors(10),main="heat.colors()")
image(volcano,col=topo.colors(0),main="topo.colors")
image(volcano,col=topo.colors(10),main="topo.colors")
par(mfrom=c(1,4))
image(volcano,col=heat.colors(10),main="heat.colors()")
image(volcano,col=topo.colors(10),main="topo.colors")
par(mfrow=c(1,4))
image(volcano,col=heat.colors(10),main="heat.colors()")
image(volcano,col=topo.colors(10),main="topo.colors")
par(mfrow=c(1,2))
image(volcano,col=heat.colors(10),main="heat.colors()")
image(volcano,col=topo.colors(10),main="topo.colors")
par(mfrow=c(1,2))
image(volcano,col=heat.colors(100),main="heat.colors()")
image(volcano,col=topo.colors(100),main="topo.colors")
image(volcano,col=heat.colors(1000),main="heat.colors()")
image(volcano,col=topo.colors(1000),main="topo.colors")
image(volcano,col=heat.colors(1000),main="heat.colors()")
image(volcano,col=topo.colors(1000),main="topo.colors")
image(volcano,col=heat.colors(50),main="heat.colors()")
image(volcano,col=topo.colors(50),main="topo.colors")
image(volcano,col=heat.colors(20),main="heat.colors()")
par(mfrow=c(1,2))
image(volcano,col=heat.colors(50),main="heat.colors()")
image(volcano,col=topo.colors(50),main="topo.colors")
)
install_from_swirl("Exploratory Data Analysis")
swirl()
install.packages("swirl")
install_from_swirl("Exploratory Data Analysis")
package(swirl)
package("swirl"")
package("swirl")
package("swirl")
packages("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
# Transform the data from the "Human Activity Recognition Using Smartphones"
# Create one R script called run_analysis.R that does the following.
#
#    1.Merges the training and the test sets to create one data set.
#    2.Extracts only the measurements on the mean and standard deviation
#      for each measurement.
#    3.Uses descriptive activity names to name the activities in the data set
#    4.Appropriately labels the data set with descriptive variable names.
#    5.From the data set in step 4, creates a second, independent tidy data set
#      with the average of each variable for each activity and each subject.
#set the working directory for the new project
prjdir<-"C:/Users/e41538/Desktop/GitHub/WK4_Project"
setwd(prjdir)
#Load some libraries I like to work with
library(downloader)
library(data.table)
library(reshape2)
library(curl)
library(dplyr)
library(tidyr)
# 0.  Get the data
source<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zippy <-"HARDATA"
download(source,zippy,mode="wb")
unzip(zippy)
#1a Load the activities
#  I'm using mydir to build file path
mydir<-"UCI HAR Dataset"
dir(mydir)
activityNames<-read.table(paste(mydir,"activity_labels.txt",sep="/"))
activityNames[,2]<-as.character(activityNames[,2])
#1b load the features and get a list of the desired features (means & std dev)
featureNames<-read.table(paste(mydir,"features.txt",sep="/"))
featureNames[,2]<-as.character(featureNames[,2])
desiredFeatures<-grep(".*mean.*|.*std.*",featureNames[,2]) #use grep to get a vector of columns
desiredFeatures.names<-featureNames[desiredFeatures,2]   #use the vector to pull the names
#1c load the data for train
typ="train"
mf<-paste(mydir,typ,sep="/")
#mf builds out the file path to the data subdirectory level (typ)
subject_train<-tbl_df(read.table(paste(mf,"subject_train.txt",sep="/")))
x_train<-tbl_df(read.table(paste(mf,"X_train.txt",sep="/")))
y_train_activities<-tbl_df(read.table(paste(mf,"y_train.txt",sep="/")))
#1d load the test
typ="test"
mf<-paste(mydir,typ,sep="/")
subject_test<-tbl_df(read.table(paste(mf,"subject_test.txt",sep="/")))
x_test<-tbl_df(read.table(paste(mf,"X_test.txt",sep="/")))
y_test_activities<-tbl_df(read.table(paste(mf,"y_test.txt",sep="/")))
#bring the subjects together
sb<-rbind(subject_train,subject_test)
colnames(sb)<-("subjectID")
# bring the summary rows together for test and train
xx<-rbind(x_train[,desiredFeatures],x_test[,desiredFeatures])
colnames(xx)<-c(desiredFeatures.names)
#cleanup column names
names(xx)<-gsub("^t","Time.",names(xx)) #expands the abreviations for time & freq
names(xx)<-gsub("^f","Freq.",names(xx))
names(xx)<-gsub("Gyro",".Gyroscope",names(xx))
names(xx)<-gsub("Mag",".Magnitude.",names(xx))
names(xx)<-gsub("Acc",".Acceleration.",names(xx))
names(xx)<-sub("\\(\\)",".",names(xx)) #handles the (()) where it is in the middle
names(xx)<-sub("\\(\\)$","",names(xx)) #handles the end of line (())
#Bring Activity together and add text values to the dataset for ease of use
act1<-rbind(y_train_activities,y_test_activities)
act<-mutate(act1,lookup(act1[,1],activityNames) )
colnames(act)<-c("activitycode","activity")
#bring columns together -Subjects, Activities and Summary Values
masData<-cbind(sb,act,xx)
#    write.table(masData,file="masdata.txt") # this is just the interim file -I wanted to do some tabs on it
## The above code completes steps 1-4 of the project
#    1.Merges the training and the test sets to create one data set.
#    2.Extracts only the measurements on the mean and standard deviation
#      for each measurement.
#    3.Uses descriptive activity names to name the activities in the data set
#    4.Appropriately labels the data set with descriptive variable names.
# Step 5  From the data set in step 4, creates a second, independent tidy data set
#      with the average of each variable for each activity and each subject.
# https://rpubs.com/bradleyboehmke/data_wrangling
# work in progress
tidy_data <- gather(masData,variableName,Value,4:82) %>%
group_by(subjectID,activity,variableName) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity)    %>%
summarise_each(c('mean')) %>%
#        group_by(subjectID,activity,variableName) %>%
#           summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
masData<-cbind(sb,act,xx)
act<-mutate(act1,lookup(act1[,1],activityNames) )
colnames(act)<-c("activitycode","activity")
#bring columns together -Subjects, Activities and Summary Values
masData<-cbind(sb,act,xx)
act1<-rbind(y_train_activities,y_test_activities)
act<-mutate(act1,lookup(act1[,1],activityNames) )
colnames(act)<-c("activitycode","activity")
#bring columns together -Subjects, Activities and Summary Values
masData<-cbind(sb,act,xx)
?lookup
??lookup
library(downloader)
library(data.table)
library(reshape2)
library(curl)
library(dplyr)
library(tidyr)
library(qdap)
# 0.  Get the data
source<-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
zippy <-"HARDATA"
download(source,zippy,mode="wb")
unzip(zippy)
#1a Load the activities
#  I'm using mydir to build file path
mydir<-"UCI HAR Dataset"
dir(mydir)
activityNames<-read.table(paste(mydir,"activity_labels.txt",sep="/"))
activityNames[,2]<-as.character(activityNames[,2])
#1b load the features and get a list of the desired features (means & std dev)
featureNames<-read.table(paste(mydir,"features.txt",sep="/"))
featureNames[,2]<-as.character(featureNames[,2])
desiredFeatures<-grep(".*mean.*|.*std.*",featureNames[,2]) #use grep to get a vector of columns
desiredFeatures.names<-featureNames[desiredFeatures,2]   #use the vector to pull the names
#1c load the data for train
typ="train"
mf<-paste(mydir,typ,sep="/")
#mf builds out the file path to the data subdirectory level (typ)
subject_train<-tbl_df(read.table(paste(mf,"subject_train.txt",sep="/")))
x_train<-tbl_df(read.table(paste(mf,"X_train.txt",sep="/")))
y_train_activities<-tbl_df(read.table(paste(mf,"y_train.txt",sep="/")))
#1d load the test
typ="test"
mf<-paste(mydir,typ,sep="/")
subject_test<-tbl_df(read.table(paste(mf,"subject_test.txt",sep="/")))
x_test<-tbl_df(read.table(paste(mf,"X_test.txt",sep="/")))
y_test_activities<-tbl_df(read.table(paste(mf,"y_test.txt",sep="/")))
#bring the subjects together
sb<-rbind(subject_train,subject_test)
colnames(sb)<-("subjectID")
# bring the summary rows together for test and train
xx<-rbind(x_train[,desiredFeatures],x_test[,desiredFeatures])
colnames(xx)<-c(desiredFeatures.names)
#cleanup column names
names(xx)<-gsub("^t","Time.",names(xx)) #expands the abreviations for time & freq
names(xx)<-gsub("^f","Freq.",names(xx))
names(xx)<-gsub("Gyro",".Gyroscope",names(xx))
names(xx)<-gsub("Mag",".Magnitude.",names(xx))
names(xx)<-gsub("Acc",".Acceleration.",names(xx))
names(xx)<-sub("\\(\\)",".",names(xx)) #handles the (()) where it is in the middle
names(xx)<-sub("\\(\\)$","",names(xx)) #handles the end of line (())
#Bring Activity together and add text values to the dataset for ease of use
act1<-rbind(y_train_activities,y_test_activities)
act<-mutate(act1,lookup(act1[,1],activityNames) )
colnames(act)<-c("activitycode","activity")
#bring columns together -Subjects, Activities and Summary Values
masData<-cbind(sb,act,xx)
#    write.table(masData,file="masdata.txt") # this is just the interim file -I wanted to do some tabs on it
## The above code completes steps 1-4 of the project
#    1.Merges the training and the test sets to create one data set.
#    2.Extracts only the measurements on the mean and standard deviation
#      for each measurement.
#    3.Uses descriptive activity names to name the activities in the data set
#    4.Appropriately labels the data set with descriptive variable names.
# Step 5  From the data set in step 4, creates a second, independent tidy data set
#      with the average of each variable for each activity and each subject.
# https://rpubs.com/bradleyboehmke/data_wrangling
# work in progress
tidy_data <- gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity)    %>%
summarise_each(c('mean')) %>%
#        group_by(subjectID,activity,variableName) %>%
#           summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- gather(masData,variableName,Value,4:82) %>%
#     group_by(subjectId, activity)    %>%
#       summarise_each(c('mean')) %>%
group_by(subjectID,activity,variableName) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
View(masData)
tidy_data <- masData
#     gather(masData,variableName,Value,4:82) %>%
#     group_by(subjectId, activity)    %>%
#       summarise_each(c('mean')) %>%
group_by(subjectID,activity,variableName) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- masData %>%
#     gather(masData,variableName,Value,4:82) %>%
#     group_by(subjectId, activity)    %>%
#       summarise_each(c('mean')) %>%
group_by(subjectID,activity,variableName) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- masData %>%
#     gather(masData,variableName,Value,4:82) %>%
#     group_by(subjectId, activity)    %>%
#       summarise_each(c('mean')) %>%
group_by(subjectID,activity) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- masData %>%
#     gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity)    %>%
summarise_each(c('mean')) %>%
#  group_by(subjectID,activity) %>%
#    summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <- masData %>%
gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity,variableName)    %>%
summarise_each(c('mean')) %>%
#  group_by(subjectID,activity) %>%
#    summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity,variableName)    %>%
summarise_each(c('mean')) %>%
#  group_by(subjectID,activity) %>%
#    summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82) %>%
group_by(subjectId, activity,variableName)    %>%
summarise_each(c('mean')) %>%
#  group_by(subjectID,activity) %>%
#    summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
group_by(tidy_data,subjectId, activity,variableName)
View(tidy_data)
tidy_data <-gather(masData,variableName,Value,4:82)
group_by(tidy_data,subjectID, activity,variableName)
summarise_each(c('mean'))
tidy_data <-gather(masData,variableName,Value,4:82)  %>%
group_by(subjectID, activity,variableName)   %>%
# summarise_each(c('mean'))
#  group_by(subjectID,activity) %>%
summarise(avg_val=mean(Value)) %>%
write.table(file="tidy_data.txt", row.name=FALSE)
View(x_train)
tidy_data <-gather(masData,variableName,Value,4:82)
View(tidy_data)
View(x_train)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_dat<-tidy_data(c("subjectID","activity","variableName","Value"))
tidy_dat<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
group_by(tidy_data,subjectID,activity,variableName)
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
summarise_each(tidy_data,c('mean'))
write.table(file="tidy_data.txt", row.name=FALSE)
write.table(tify_data,file="tidy_data.txt", row.name=FALSE)
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
x<-summarise(tidy_data,avg_val=mean(Value))
library(dplyr)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
# summarise_each(tidy_data,c('mean'))
#  group_by(subjectID,activity) %>%
x<-summarise(tidy_data,avg_val=mean(Value)) %>%
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
summarise(tidy_data,avg_val=mean(Value))
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
summarise(tidy_data,avg_val=mean(Value))
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity)
# summarise_each(tidy_data,c('mean'))
#  group_by(subjectID,activity) %>%
summarise(tidy_data,avg_val=mean(Value))
tidy_data<-group_by(tidy_data,subjectID,activity)
# summarise_each(tidy_data,c('mean'))
#  group_by(subjectID,activity) %>%
summarise(tidy_data,avg_val=mean(Value))
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
# summarise_each(tidy_data,c('mean'))
#  group_by(subjectID,activity) %>%
summarise(tidy_data,avg_val=mean(Value)) %>%
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
# summarise_each(tidy_data,c('mean'))
#  group_by(subjectID,activity) %>%
summarise(tidy_data,avg_val=mean(Value))
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
summarise(tidy_data,avg_val=mean(Value)) %>%
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
summarise(tidy_data,avg_val=mean(Value))
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
summarise(tidy_data,avg_val=mean(Value))
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
tidy_data<-summarise(tidy_data,avg_val=mean(Value))
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data<-tidy_data[,c("subjectID","activity","variableName","Value")]
tidy_data<-group_by(tidy_data,subjectID,activity,variableName)
tidy_data<-summarise(tidy_data,avg_val=mean(Value))
write.table(tidy_data,file="tidy_data.txt", row.name=FALSE)
View(tidy_data)
head(tidy_data)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data[,c("subjectID","activity","variableName","Value")] %>%
group_by(subjectID,activity,variableName)              %>%
summarise(avg_val=mean(Value))                     %>%
write.table(file="tidy_data.txt", row.name=FALSE)
tidy_data <-gather(masData,variableName,Value,4:82)
tidy_data[,c("subjectID","activity","variableName","Value")] %>%
group_by(subjectID,activity,variableName)              %>%
summarise(avg_val=mean(Value))                     %>%
write.table(file="tidy_data.txt", row.name=FALSE)
